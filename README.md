# Akura: Adaptive Sinhala Learning for Early Childhood

## Overview

Akura is a research-driven, adaptive learning platform designed to support early childhood education for Sinhala-speaking children in Sri Lanka. The project integrates **gesture recognition, handwriting analysis, speech-based pronunciation feedback, and emotion-aware adaptation** to address long-standing limitations in traditional preschool education, such as rote memorization, large studentâ€“teacher ratios, and lack of personalized feedback.

The system is designed as a **mobile, offline-first application**, ensuring accessibility in resource-constrained and low-connectivity environments while maintaining strong privacy safeguards.

---

## Research Motivation

Early childhood learning in Sri Lanka faces several persistent challenges:

* Overreliance on rote learning and worksheets
* Limited personalization due to high studentâ€“teacher ratios
* Insufficient real-time corrective feedback
* Language barriers for bilingual or overseas Sinhala-speaking children
* Lack of culturally and linguistically adapted educational technologies

Akura addresses these gaps by combining **multimodal interaction** with **adaptive learning strategies**, grounded in early childhood education and humanâ€“computer interaction research.

---

## Project Status

ðŸš§ **Ongoing Research & Development**
This project is currently under active implementation as part of an academic research study. Core system components are being developed and integrated incrementally.

---

### Branching Model & Version Control
We strictly follow the **GitHub Flow** branching model to ensure organized development and a full project history:
* **Main Branch:** Holds the stable, production-ready code.
* **Feature Branches:** Individual modules are developed in dedicated branches.

---  

## System Overview
<img width="949" height="576" alt="image" src="https://github.com/user-attachments/assets/52de0d9a-4921-46f4-9e73-38a1439788a5" />


---

### Technical Dependencies
* **Framework:** Flutter & Dart (Cross-platform UI).
* **Machine Learning:** TensorFlow Lite (`.tflite`) for Emotion and Voice models.
* **Native Integration:** Google MediaPipe (Native Android/iOS) for Gesture/Number recognition.
* **Graphics:** Custom SVG path-processing for real-time handwriting validation.

---

## Major Breakthroughs
* **Project Completion Status:** Successfully reached over 50% completion of the total planned research and development objectives.

---

## Contributors

* Research Team â€“ **Akura Project**
* **Mihiran:** Real-time Handwriting component.
* **Rahul:** Pronunciation Practice & Voice modeling.
* **Dhuwindhu:** Emotion-aware adaptation.
* **Dinithi:** MediaPipe setup & Gesture-based number learning.

---

## License

This project is developed for **academic and research purposes**. Licensing details will be updated upon publication.
